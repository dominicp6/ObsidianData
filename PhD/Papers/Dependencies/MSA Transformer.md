The MSA Transformer is a type of neural network architecture that operates on sets of aligned sequences, specifically multiple sequence alignments (MSAs) of protein sequences.

The MSA Transformer is an unsupervised protein language model that uses the MSA of a query sequence instead of a single query sequence.Â The model is composed of a stack of attention blocks, with each block consisting of a row attention layer, a column attention layer, and a feed-forward layer.

The MSA Transformer is designed to extract the characteristics of proteins from their MSA profiles efficiently, and has been shown to achieve high accuracy in predicting protein structural properties, such as secondary structure prediction and mutational effects.

It is a key component of several recent protein modelling and prediction methods such as A-Prot and S-Pred.



